{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b4db00",
   "metadata": {},
   "source": [
    "## ğŸ§  PCA Nedir? (En Temelden)\n",
    "\n",
    "**PCA**, TÃ¼rkÃ§esiyle *Temel BileÅŸenler Analizi*, veriyi daha az sayÄ±da ama daha anlamlÄ± boyutlara indirgemek iÃ§in kullanÄ±lan bir yÃ¶ntemdir.\n",
    "\n",
    "> \"Elimizde Ã§ok fazla sÃ¼tun varsa ve hepsi birbiriyle biraz alakalÄ±ysa, bu bilgiyi Ã¶zetlemenin yoludur.\"\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’ Benzetme ile AnlatÄ±m: \"Seyahat Ã‡antasÄ±\"\n",
    "\n",
    "Diyelim ki bir yere tatile gideceksin ama sadece kÃ¼Ã§Ã¼k bir Ã§anta hakkÄ±n var. DolabÄ±ndaki her ÅŸeyi alamazsÄ±n. O yÃ¼zden:\n",
    "\n",
    "- GÃ¶mlek yerine 2 tane en sevdiÄŸini alÄ±rsÄ±n,\n",
    "- AyakkabÄ± yerine en Ã§ok iÅŸine yarayacak 1 taneyi,\n",
    "- Ve genel olarak en fazla bilgiyi taÅŸÄ±yan parÃ§alarÄ± Ã§antaya koyarsÄ±n.\n",
    "\n",
    "**Ä°ÅŸte PCA da aynen bunu yapar.**\n",
    "\n",
    "- Elindeki **Ã§ok sayÄ±da bilgiden**, en fazla *varyans* (bilgi Ã§eÅŸitliliÄŸi) taÅŸÄ±yan bileÅŸenleri alÄ±r.\n",
    "- Bu yeni bileÅŸenler, orijinal deÄŸiÅŸkenlerden tÃ¼retilmiÅŸ, Ã¶zet halidir.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š PCA Ne Ä°ÅŸe Yarar?\n",
    "\n",
    "1. **Boyut Ä°ndirgeme:**  \n",
    "   YÃ¼zlerce sÃ¼tunu (Ã¶zelliÄŸi) birkaÃ§ \"temel bileÅŸene\" indirerek veriyi daha anlaÅŸÄ±lÄ±r hale getirir.\n",
    "\n",
    "2. **GÃ¶rselleÅŸtirme:**  \n",
    "   Veriyi 2D veya 3D'ye indirip Ã§izim yapÄ±labilir hale getirir (Ã¶zellikle kÃ¼meleri gÃ¶rmek iÃ§in).\n",
    "\n",
    "3. **HÄ±zlandÄ±rma:**  \n",
    "   Daha az boyut â†’ daha az hesaplama â†’ daha hÄ±zlÄ± algoritmalar\n",
    "\n",
    "4. **Noise Filtering:**  \n",
    "   GÃ¼rÃ¼ltÃ¼lÃ¼ ya da Ã¶nemsiz verileri ortadan kaldÄ±rÄ±r.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ PCA NasÄ±l Ã‡alÄ±ÅŸÄ±r?\n",
    "\n",
    "AdÄ±m adÄ±m anlatayÄ±m:\n",
    "\n",
    "### 1. **Veriyi StandartlaÅŸtÄ±r (Zorunlu!)**  \n",
    "   Ã‡Ã¼nkÃ¼ PCA, deÄŸiÅŸkenlerin birimlerinden etkilenir. Hepsini aynÄ± Ã¶lÃ§ekte dÃ¼ÅŸÃ¼nmeliyiz.\n",
    "\n",
    "### 2. **Kovaryans Matrisi Hesapla**  \n",
    "   Hangi deÄŸiÅŸken hangisiyle ne kadar iliÅŸkili? Buna bakar.\n",
    "\n",
    "### 3. **Ã–zdeÄŸerler ve Ã–zvektÃ¶rleri Hesapla**  \n",
    "   En fazla bilgi iÃ§eren yÃ¶nleri (vektÃ¶rleri) bulur.\n",
    "\n",
    "### 4. **Yeni Koordinatlara Projeksiyon (DÃ¶nÃ¼ÅŸtÃ¼rme)**  \n",
    "   Veriyi, bu \"en anlamlÄ± eksenler\" Ã¼zerine taÅŸÄ±yarak yeni bir uzayda temsil eder.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Neden â€œPrincipal Componentâ€ Deniyor?\n",
    "\n",
    "Ã‡Ã¼nkÃ¼:\n",
    "- Bunlar verinin en temel (principal) Ã¶zet yÃ¶nleri.\n",
    "- Ä°lk bileÅŸen = En Ã§ok bilgiyi taÅŸÄ±yan yÃ¶n\n",
    "- Ä°kinci bileÅŸen = Ä°kinci en Ã§ok bilgiyi taÅŸÄ±yan (ama ilkiyle dik aÃ§Ä± yapan) yÃ¶n\n",
    "- Ve bÃ¶yle devam eder...\n",
    "\n",
    "---\n",
    "\n",
    "## â“Peki KaÃ§ BileÅŸen SeÃ§meliyiz?\n",
    "\n",
    "Ä°ÅŸte burada ÅŸu sihirli soru gelir:  \n",
    "**â€œKaÃ§ boyuta indirsem yeter?â€**\n",
    "\n",
    "ğŸ‘‰ Genelde ÅŸunu yaparÄ±z:\n",
    "\n",
    "```python\n",
    "pca = PCA().fit(X_scaled)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "```\n",
    "\n",
    "> EÄŸer ilk 2 bileÅŸen verinin %95â€™ini aÃ§Ä±klÄ±yorsa, bu iki bileÅŸenle Ã§alÄ±ÅŸmak mantÄ±klÄ±dÄ±r.\n",
    "\n",
    "Bu grafik bize:  \n",
    "âœ” Her bileÅŸen ne kadar bilgi taÅŸÄ±yor  \n",
    "âœ” Nerede â€œdoygunlukâ€ var, yani daha fazla bileÅŸen almak anlamlÄ± deÄŸil\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘©â€ğŸ”¬ GerÃ§ek Hayattan Ã–rnek: Kredi KartÄ± Verisi\n",
    "\n",
    "Kredi kartÄ± dolandÄ±rÄ±cÄ±lÄ±k verisi genellikle 30+ deÄŸiÅŸkenden oluÅŸur.\n",
    "\n",
    "- Bu deÄŸiÅŸkenlerin Ã§oÄŸu birbiriyle iliÅŸkili.\n",
    "- PCA uyguladÄ±ÄŸÄ±nda, ilk birkaÃ§ bileÅŸen toplam bilginin bÃ¼yÃ¼k kÄ±smÄ±nÄ± temsil edebiliyor.\n",
    "- Bu da hem **gÃ¶rselleÅŸtirme** hem de **anomaly detection** iÃ§in harika bir hazÄ±rlÄ±k adÄ±mÄ± oluyor.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Ã–zetle:\n",
    "\n",
    "| PCA HakkÄ±nda GerÃ§ekler      | AÃ§Ä±klama                                 |\n",
    "|-----------------------------|------------------------------------------|\n",
    "| Ne iÅŸe yarar?               | Boyut indirgeme, veri Ã¶zetleme           |\n",
    "| Neye gÃ¶re karar verir?      | Varyans (bilgi miktarÄ±)                  |\n",
    "| Lineer mi Ã§alÄ±ÅŸÄ±r?          | Evet, sadece doÄŸrusal iliÅŸkilerle       |\n",
    "| PCA ile veri bozulur mu?    | Az da olsa, ama Ã¶nemli bilgi korunur     |\n",
    "| DÃ¼ÅŸÃ¼k boyutlar ne saÄŸlar?   | HÄ±z, basitlik, daha iyi gÃ¶rselleÅŸtirme   |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
