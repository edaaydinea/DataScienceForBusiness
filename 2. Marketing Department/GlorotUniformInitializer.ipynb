{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7486a1",
   "metadata": {},
   "source": [
    "## ğŸ¯ Glorot Uniform Initializer Nedir?\n",
    "\n",
    "> **Glorot uniform initializer**, sinir aÄŸÄ± aÄŸÄ±rlÄ±klarÄ±nÄ±n baÅŸlangÄ±Ã§ta hangi deÄŸerlere atanacaÄŸÄ±nÄ± belirleyen bir yÃ¶ntemdir.\n",
    "\n",
    "Yani bu initializer, **her nÃ¶ronun aÄŸÄ±rlÄ±klarÄ±nÄ± rastgele ama kontrollÃ¼** bir ÅŸekilde baÅŸlatÄ±r. Ama Ã¶yle rastgele deÄŸil â€” **istatistiksel zekÃ¢yla** rastgele. Ã‡Ã¼nkÃ¼ yanlÄ±ÅŸ bir baÅŸlangÄ±Ã§, modelin Ã¶ÄŸrenmesini **ya yavaÅŸlatÄ±r ya da tamamen mahveder**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Neden Ä°htiyacÄ±mÄ±z Var?\n",
    "\n",
    "EÄŸer aÄŸÄ±rlÄ±klarÄ±:\n",
    "- **Ã‡ok kÃ¼Ã§Ã¼k baÅŸlatÄ±rsak**: Gradient'ler yok olur (â†’ **vanishing gradient**),\n",
    "- **Ã‡ok bÃ¼yÃ¼k baÅŸlatÄ±rsak**: Gradient'ler patlar (â†’ **exploding gradient**).\n",
    "\n",
    "Ä°ÅŸte tam bu noktada Glorot devreye giriyor:\n",
    "> AÄŸÄ±rlÄ±klarÄ± Ã¶yle bir aralÄ±kta baÅŸlat ki, hem **forward pass** (aktivasyonlar), hem de **backward pass** (gradientler) katmanlar arasÄ±nda istikrarlÄ± kalsÄ±n.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“œ Glorot'un FormÃ¼lÃ¼:\n",
    "\n",
    "Glorot uniform ÅŸunu der:\n",
    "```python\n",
    "limit = sqrt(6 / (fan_in + fan_out))\n",
    "```\n",
    "\n",
    "Sonra aÄŸÄ±rlÄ±klar ÅŸu aralÄ±ktan rastgele seÃ§ilir:\n",
    "```python\n",
    "[-limit, +limit]\n",
    "```\n",
    "\n",
    "- `fan_in` â†’ Bu katmana giren nÃ¶ron sayÄ±sÄ±\n",
    "- `fan_out` â†’ Bu katmandan Ã§Ä±kan nÃ¶ron sayÄ±sÄ±\n",
    "\n",
    "> ğŸ“ Bu formÃ¼l, Glorot & Bengioâ€™nun 2010â€™daki makalesinden geliyor:  \n",
    "> _\"Understanding the difficulty of training deep feedforward neural networks\"_\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Autoencoder'da Ne Ä°ÅŸe Yarar?\n",
    "\n",
    "Autoencoder'larda encoder ve decoder arasÄ±nda veri \"sÄ±kÄ±ÅŸÄ±r\" â†’ hassas ve dengeli bir Ã¶ÄŸrenme gerekir.  \n",
    "Ä°ÅŸte burada **Glorot uniform** harika Ã§alÄ±ÅŸÄ±r Ã§Ã¼nkÃ¼:\n",
    "\n",
    "### ğŸ§¬ 1. **Veri akÄ±ÅŸÄ±nÄ± dengeler (forward pass)**  \n",
    "- Encoder'dan latent'e, oradan decoder'a geÃ§erken sinyallerin bozulmamasÄ±nÄ± saÄŸlar.\n",
    "\n",
    "### ğŸ§  2. **Backpropagation sÄ±rasÄ±nda gradientlerin dengesini korur**  \n",
    "- BÃ¶ylece model dÃ¼zgÃ¼n Ã¶ÄŸrenir. Ne Ã§ok yavaÅŸ, ne de patlayarak.\n",
    "\n",
    "### ğŸ” 3. **Sembolikte â€œsimetrikâ€ bir yapÄ± olduÄŸu iÃ§in daha da kritik**\n",
    "- Encoder ve decoder simetrik yapÄ±lar â†’ aynÄ± initializer kullanmak, Ã¶ÄŸrenmeyi daha kararlÄ± kÄ±lar.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Kerasâ€™ta NasÄ±l KullanÄ±lÄ±r?\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "encoded = Dense(32, activation='relu', kernel_initializer=GlorotUniform())(input_layer)\n",
    "```\n",
    "\n",
    "Not: Kerasâ€™ta zaten varsayÄ±lan initializer genelde `glorot_uniform`, yani belirtmesen bile Ã§oÄŸu zaman zaten bunu kullanÄ±yor. Ama bilinÃ§li kullanmak iyidir ğŸ’¡\n",
    "\n",
    "---\n",
    "\n",
    "## âš”ï¸ Glorot vs DiÄŸer Initializerâ€™lar\n",
    "\n",
    "| Initializer       | KullanÄ±m Yeri                         |\n",
    "|-------------------|----------------------------------------|\n",
    "| **Glorot Uniform** | Genellikle ReLU dÄ±ÅŸÄ±ndaki aktivasyonlar (tanh, sigmoid) |\n",
    "| **He Initialization** | ReLU ve tÃ¼revleri (LeakyReLU, ELU) iÃ§in daha iyi |\n",
    "| **LeCun**         | Sigmoid/selu gibi Ã¶zel durumlar        |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ KapanÄ±ÅŸ Notu:\n",
    "\n",
    "- Autoencoder gibi derin yapÄ±larda, aÄŸÄ±rlÄ±klarÄ±n doÄŸru baÅŸlatÄ±lmasÄ± **Ã¶ÄŸrenmenin kaderini belirler.**\n",
    "- Glorot, bu iÅŸin matematiksel temelli, dengeli ve gÃ¼venilir yÃ¶ntemidir.\n",
    "- Ã–ÄŸrenme hÄ±zÄ±nÄ± artÄ±rÄ±r, modelin daha saÄŸlÄ±klÄ± konverge etmesini saÄŸlar."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
