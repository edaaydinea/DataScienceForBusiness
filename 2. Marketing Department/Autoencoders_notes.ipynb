{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87570e89",
   "metadata": {},
   "source": [
    "Hazır PCA’ya sağlam bir temel attık, şimdi sırada onun “derin öğrenme kuzeni” olan Autoencoder var. Yani PCA lineer bir yöntemse, Autoencoder onun sinir ağı versiyonu, daha doğrusu non-lineer boyut indirgeme ustası."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64759f4",
   "metadata": {},
   "source": [
    "## 🤖 Autoencoder Nedir?\n",
    "\n",
    "> **Autoencoder**, bir tür yapay sinir ağıdır ve temel görevi:  \n",
    "> **Veriyi kendisinden yeniden üretmek**.\n",
    "\n",
    "Ama işin aslı şu:  \n",
    "Autoencoder, veriyi önce **sıkıştırır** (encode eder), sonra **geri açar** (decode eder).\n",
    "\n",
    "Amaç, **girişe çok benzeyen bir çıkış** elde etmektir — fakat veriyi önce dar bir \"gizli katmana\" sıkıştırmak zorunda kaldığı için, yalnızca en önemli bilgileri tutmak zorundadır.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Yapısı Nasıldır?\n",
    "\n",
    "### Basit bir Autoencoder 3 ana parçadan oluşur:\n",
    "\n",
    "```\n",
    "INPUT → [Encoder] → [Latent Space / Bottleneck] → [Decoder] → OUTPUT\n",
    "```\n",
    "\n",
    "### 1. **Encoder:**\n",
    "- Veriyi küçültür, bir nevi özetini çıkarır.\n",
    "- Örn: 784 boyutlu bir MNIST görüntüsünü alır, 32 boyutlu bir \"latent vektör\" üretir.\n",
    "\n",
    "### 2. **Latent Space (Gizli Temsil):**\n",
    "- **Verinin en sıkıştırılmış hali**.\n",
    "- Bu nokta, tıpkı PCA’daki principal components gibi, veriyi daha küçük boyutta ama bilgi açısından zengin şekilde temsil eder.\n",
    "\n",
    "### 3. **Decoder:**\n",
    "- Latent vektörü kullanarak, giriş verisini yeniden oluşturmaya çalışır.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Amaç Nedir?\n",
    "\n",
    "> **Reconstruction Error’u** (yeniden üretme hatasını) minimize etmek.\n",
    "\n",
    "Yani:\n",
    "\n",
    "```python\n",
    "Loss = ||input - output||²\n",
    "```\n",
    "\n",
    "Model, öğrenme sırasında input’a çok benzeyen bir output üretmeyi öğrenir. Ama bu sırada sadece birkaç nöronla bu işi yapmaya çalıştığı için, **verideki en anlamlı desenleri** öğrenmek zorunda kalır.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Neden Kullanılır?\n",
    "\n",
    "1. **Boyut İndirgeme (Non-linear PCA):**  \n",
    "   PCA sadece lineer ilişkileri öğrenebilirken, Autoencoder karmaşık (nonlinear) yapıları da yakalayabilir.\n",
    "\n",
    "2. **Gürültü Temizleme (Denoising):**  \n",
    "   Noisy bir input verilir, ama temiz versiyonu target yapılır → Model gürültüyü ayıklamayı öğrenir.\n",
    "\n",
    "3. **Anomali Tespiti:**  \n",
    "   Model, “normal” verileri öğrenir. Anormal bir şey gelince doğru şekilde reconstruct edemez → Reconstruction error yükselir → Anomali olarak işaretlenir.\n",
    "\n",
    "4. **Veri Sıkıştırma:**  \n",
    "   Verinin sadece öz bilgisini tutar, disk/tampon bellek gibi yerlerde kullanılır.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 PCA vs Autoencoder\n",
    "\n",
    "| Özellik                  | PCA                          | Autoencoder                          |\n",
    "|--------------------------|-------------------------------|---------------------------------------|\n",
    "| Doğrusal mı?             | Evet                          | Hayır (Non-lineer desenler yakalar)   |\n",
    "| Model tipi               | Matris cebiri                 | Sinir ağı                             |\n",
    "| Yorumlanabilirlik        | Daha yüksek                   | Daha düşük                            |\n",
    "| Derin yapılar mümkün mü? | Hayır                         | Evet (Stacked Autoencoder yapılabilir) |\n",
    "| Anomali tespiti?         | Zor                           | Harika                                |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Basit Bir Autoencoder Kodu (Keras)\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=64, validation_split=0.1)\n",
    "```\n",
    "\n",
    "Modelin çıktısı:  \n",
    "- `X_train`’i kendine çok yakın şekilde yeniden üretmeye çalışır.\n",
    "- Eğer `X_anomaly` verilerini verirsen, reconstruction hatası yükselir → tespit edebilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Örnek Uygulama: Kredi Kartı Dolandırıcılığı\n",
    "\n",
    "- Dolandırıcılık verileri, genellikle çok az sayıda outlier içerir.\n",
    "- Autoencoder, normal verileri çok iyi öğrenir.\n",
    "- Ama dolandırıcılık gibi “alışılmadık” verileri reconstruct edemez.\n",
    "- Reconstruction Error > Threshold ise → Bu veri bir anomali!\n",
    "\n",
    "---\n",
    "\n",
    "## 🎁 Bonus: Farklı Autoencoder Türleri\n",
    "\n",
    "- **Denoising Autoencoder:** Gürültülü veriden temiz veri üretmeye çalışır.\n",
    "- **Sparse Autoencoder:** Latent alanı seyrekleştirerek öğrenmeyi zorlar.\n",
    "- **Variational Autoencoder (VAE):** Üretken (generative) bir versiyon. Latent space’i olasılıksal öğrenir → Yeni veri örnekleri üretebilir.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Kısaca Özetle\n",
    "\n",
    "| Terim | Anlam |\n",
    "|------|-------|\n",
    "| Encoder | Sıkıştırıcı (input → latent) |\n",
    "| Decoder | Açıcı (latent → output) |\n",
    "| Latent Space | Gizli anlamlı vektör |\n",
    "| Reconstruction Error | Modelin \"ne kadar iyi hatırladığı\" |\n",
    "| Anomaly Detection | “Hatırlayamadığın şeyler” → potansiyel sorunlar |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
